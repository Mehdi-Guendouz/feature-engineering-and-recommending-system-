{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c268cc43",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-19T16:57:46.480223Z",
     "iopub.status.busy": "2023-12-19T16:57:46.479165Z",
     "iopub.status.idle": "2023-12-19T16:57:46.930684Z",
     "shell.execute_reply": "2023-12-19T16:57:46.929321Z"
    },
    "papermill": {
     "duration": 0.460116,
     "end_time": "2023-12-19T16:57:46.934110",
     "exception": false,
     "start_time": "2023-12-19T16:57:46.473994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef31d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T16:57:46.942047Z",
     "iopub.status.busy": "2023-12-19T16:57:46.941526Z",
     "iopub.status.idle": "2023-12-19T16:57:46.998530Z",
     "shell.execute_reply": "2023-12-19T16:57:46.996743Z"
    },
    "papermill": {
     "duration": 0.063924,
     "end_time": "2023-12-19T16:57:47.001180",
     "exception": false,
     "start_time": "2023-12-19T16:57:46.937256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gains:\n",
      "Temperature_Category: 0.9852281360342513\n",
      "Cloud Cover: 0.9852281360342513\n",
      "Humidity: 0.6995138503199656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Temperature': [75, 80, 85, 70, 65, 60, 90],\n",
    "    'Cloud Cover': ['Sunny', 'Partly Cloudy', 'Overcast', 'Sunny', 'Overcast', 'Partly Cloudy', 'Overcast'],\n",
    "    'Humidity': ['Low', 'High', 'High', 'Medium', 'Medium', 'Low', 'High'],\n",
    "    'Weather': ['Sunny', 'Sunny', 'Rainy', 'Sunny', 'Stormy', 'Sunny', 'Rainy']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Discretize the feature Temperature\n",
    "temperature_bins = [0, 70, 80, 100]\n",
    "temperature_labels = ['warm', 'hot', 'very hot']\n",
    "df['Temperature_Category'] = pd.cut(df['Temperature'], bins=temperature_bins, labels=temperature_labels)\n",
    "\n",
    "# 2. Calculate the Entropy of the target class Weather\n",
    "def calculate_entropy(target_column):\n",
    "    unique_values, counts = np.unique(target_column, return_counts=True)\n",
    "    probabilities = counts / len(target_column)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "entropy_weather = calculate_entropy(df['Weather'])\n",
    "\n",
    "# 3. Calculate Information Gain for each feature\n",
    "def calculate_information_gain(data, feature, target):\n",
    "    entropy_total = calculate_entropy(data[target])\n",
    "    unique_values = data[feature].unique()\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    for value in unique_values:\n",
    "        subset = data[data[feature] == value]\n",
    "        entropy_subset = calculate_entropy(subset[target])\n",
    "        weight = len(subset) / len(data)\n",
    "        weighted_entropy += weight * entropy_subset\n",
    "    \n",
    "    information_gain = entropy_total - weighted_entropy\n",
    "    return information_gain\n",
    "\n",
    "# Calculate Information Gain for each feature\n",
    "information_gains = {}\n",
    "features = ['Temperature_Category', 'Cloud Cover', 'Humidity']\n",
    "\n",
    "for feature in features:\n",
    "    information_gain = calculate_information_gain(df, feature, 'Weather')\n",
    "    information_gains[feature] = information_gain\n",
    "\n",
    "# 4. Order the features according to their IG\n",
    "sorted_features = sorted(information_gains.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display results\n",
    "print(\"Information Gains:\")\n",
    "for feature, ig in sorted_features:\n",
    "    print(f\"{feature}: {ig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66a2f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T16:57:47.009306Z",
     "iopub.status.busy": "2023-12-19T16:57:47.008850Z",
     "iopub.status.idle": "2023-12-19T16:57:47.066442Z",
     "shell.execute_reply": "2023-12-19T16:57:47.064207Z"
    },
    "papermill": {
     "duration": 0.065282,
     "end_time": "2023-12-19T16:57:47.069532",
     "exception": false,
     "start_time": "2023-12-19T16:57:47.004250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Original Data\n",
      "     x     y    z\n",
      "R1  12  24.0  6.0\n",
      "R2  17  15.5 -2.0\n",
      "R3  12  13.0  3.0\n",
      "R4   6  13.5 -2.5\n",
      "R5  17  21.0  7.2\n",
      "R6   4  20.3 -0.9\n",
      "\n",
      "Step 1: Mean Values\n",
      "x    11.333333\n",
      "y    17.883333\n",
      "z     1.800000\n",
      "dtype: float64\n",
      "\n",
      "Step 1: Standard Deviation Values\n",
      "x    5.428321\n",
      "y    4.510174\n",
      "z    4.206186\n",
      "dtype: float64\n",
      "\n",
      "Step 2: Standardized Data\n",
      "           x         y         z\n",
      "R1  0.122813  1.356193  0.998529\n",
      "R2  1.043908 -0.528435 -0.903431\n",
      "R3  0.122813 -1.082737  0.285294\n",
      "R4 -0.982502 -0.971877 -1.022304\n",
      "R5  1.043908  0.691030  1.283823\n",
      "R6 -1.350940  0.535826 -0.641912\n",
      "\n",
      "Step 3: Covariance Matrix\n",
      "[[1.         0.08686417 0.48527262]\n",
      " [0.08686417 1.         0.61189326]\n",
      " [0.48527262 0.61189326 1.        ]]\n",
      "\n",
      "Step 4: Eigenvalues\n",
      "[1.82462432 0.91547483 0.25990085]\n",
      "\n",
      "Step 4: Eigenvectors\n",
      "[[-0.46348371 -0.78498896 -0.41106591]\n",
      " [-0.55899398  0.61896667 -0.55173   ]\n",
      " [-0.68753806  0.0259345   0.72568507]]\n",
      "\n",
      "Step 5: Sorted Eigenvalues\n",
      "[1.82462432 0.91547483 0.25990085]\n",
      "\n",
      "Step 5: Sorted Eigenvectors\n",
      "[[-0.46348371 -0.78498896 -0.41106591]\n",
      " [-0.55899398  0.61896667 -0.55173   ]\n",
      " [-0.68753806  0.0259345   0.72568507]]\n",
      "\n",
      "Step 6: Explained Variance Ratio\n",
      "[0.60820811 0.30515828 0.08663362]\n",
      "\n",
      "Step 6: Cumulative Explained Variance\n",
      "[0.60820811 0.91336638 1.        ]\n",
      "\n",
      "Step 6: Number of Components to Keep\n",
      "2\n",
      "\n",
      "Step 7: Projection Matrix\n",
      "[[-0.46348371 -0.78498896]\n",
      " [-0.55899398  0.61896667]\n",
      " [-0.68753806  0.0259345 ]]\n",
      "\n",
      "Step 8: Reduced Data Matrix R\n",
      "[[-1.5015524   0.76892812]\n",
      " [ 0.43270106 -1.16996978]\n",
      " [ 0.35217141 -0.75918595]\n",
      " [ 1.70151954  0.14318052]\n",
      " [-1.75279352 -0.35843609]\n",
      " [ 0.76795392  1.37548319]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Provided dataset\n",
    "data = {\n",
    "    'x': [12, 17, 12, 6, 17, 4],\n",
    "    'y': [24, 15.5, 13, 13.5, 21, 20.3],\n",
    "    'z': [6, -2, 3, -2.5, 7.2, -0.9],\n",
    "}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data, index=['R1', 'R2', 'R3', 'R4', 'R5', 'R6'])\n",
    "\n",
    "print(\"Step 0: Original Data\")\n",
    "print(df)\n",
    "\n",
    "# Step 1: Calculate mean and standard deviation for each variable (X, Y, Z)\n",
    "mean_values = df.mean()\n",
    "std_dev_values = df.std()\n",
    "\n",
    "print(\"\\nStep 1: Mean Values\")\n",
    "print(mean_values)\n",
    "print(\"\\nStep 1: Standard Deviation Values\")\n",
    "print(std_dev_values)\n",
    "\n",
    "# Step 2: Standardize the data using Z-score\n",
    "standardized_data = (df - mean_values) / std_dev_values\n",
    "\n",
    "print(\"\\nStep 2: Standardized Data\")\n",
    "print(standardized_data)\n",
    "\n",
    "# Step 3: Calculate the covariance matrix\n",
    "covariance_matrix = np.cov(standardized_data, rowvar=False)\n",
    "\n",
    "print(\"\\nStep 3: Covariance Matrix\")\n",
    "print(covariance_matrix)\n",
    "\n",
    "# Step 4: Find eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "print(\"\\nStep 4: Eigenvalues\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nStep 4: Eigenvectors\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 5: Sort eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "print(\"\\nStep 5: Sorted Eigenvalues\")\n",
    "print(eigenvalues)\n",
    "print(\"\\nStep 5: Sorted Eigenvectors\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# Step 6: Decide how many principal components to keep\n",
    "total_variance = np.sum(eigenvalues)\n",
    "explained_variance_ratio = eigenvalues / total_variance\n",
    "\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "num_components_to_keep = np.argmax(cumulative_explained_variance >= 0.9) + 1\n",
    "\n",
    "print(\"\\nStep 6: Explained Variance Ratio\")\n",
    "print(explained_variance_ratio)\n",
    "print(\"\\nStep 6: Cumulative Explained Variance\")\n",
    "print(cumulative_explained_variance)\n",
    "print(\"\\nStep 6: Number of Components to Keep\")\n",
    "print(num_components_to_keep)\n",
    "\n",
    "# Step 7: Form the projection matrix V\n",
    "projection_matrix = eigenvectors[:, :num_components_to_keep]\n",
    "\n",
    "print(\"\\nStep 7: Projection Matrix\")\n",
    "print(projection_matrix)\n",
    "\n",
    "# Step 8: Calculate the reduced data matrix R\n",
    "reduced_data = np.dot(standardized_data, projection_matrix)\n",
    "\n",
    "print(\"\\nStep 8: Reduced Data Matrix R\")\n",
    "print(reduced_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81307e15",
   "metadata": {
    "papermill": {
     "duration": 0.003324,
     "end_time": "2023-12-19T16:57:47.076391",
     "exception": false,
     "start_time": "2023-12-19T16:57:47.073067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.826109,
   "end_time": "2023-12-19T16:57:47.603456",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-19T16:57:42.777347",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
